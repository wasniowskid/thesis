\subsection{Przetwarzanie danych}

Lawinowo rosnąca liczba nowych urządzeń podłączanych do sieci
oraz wzrost tempa generowania danych przez nie spodował,
że konieczne się stało stworzenie nowych metod ich analizy.

Dane wykorzystywane w zbiorach \textit{Big Data} można opisać modelem \textit{3V} (Gartner Inc., 2012):
\begin{itemize}
		\item \textbf{Volume} - ilość,
		której nie można przetworzyć z wykorzystaniem standardowych metod i narzędzi.
		\item \textbf{Velocity} - zmienność.
		Dane napływają z różną czestotliwością (natężeniem),
		często w tym samym momencie.
		\item \textbf{Variety} - różnorodność.
		Dane pochodzą pochodzą z wielu źródeł źródeł.
		Mogą nie być ustrukturyzowane.
		Być w różnych formatach.
\end{itemize}


Obecnie na rynku dostępnych jest wiele rozwiązań oferujących analizę strumieniową.
Poprzez rozwiązania komercyjne od gigantów jak Microsoft, Google, Amazon,
po typu open-source,
takie jak Apache Storm, Apache Spark czy Apache Flink.
W ramach przygotowań przed rozpoczęciem prac została dokonana analiza
możliwości i przydatności 3 platform:
\begin{enumerate}
	\item Esper,
	\item Apache Spark,
	\item Apache Storm.
\end{enumerate}
Przy wyborze porównywanych rozwiązań wzięto pod uwagę
łatwość korzystania,
dojrzałość rynkową
oraz aktywną społeczność.


% cep
% big data
% real time
% hadoop shorter times

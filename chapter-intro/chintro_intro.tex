Szacuje się,
że obecnie w użyciu jest 2 mld komputerów,
10 mld telefonów komórkowych,
a do 2020 r. do sieci ma być podłączone 20 mld urządzeń (Gartner, Inc., 2015).
Urządzenia te będą zbierać dane,
przetwarzać je
bądź przekazywać dalej.
Dzięki temu ludzie będą mogli wiedzieć więcej na temat otaczającego świata,
szybciej reagować na zmiany
czy podejmować lepsze decyzje.
Ogromne ilości danych generowane w każdej sekundzie,
oraz wymagania użytkowników aby wyniki otrzymywać coraz szybciej,
najlepiej od razu,
powodują,
że obecne metody przetwarzania danych stają się niewystarczające.
Wśród rozwiązań pozwalających radzić sobie w takich sytuacjach
coraz większą popularność zyskuje przetwarzanie strumieniowe (\textit{stream analysis, data streaming}).

Rozwiązania oparte na przetwarzaniu strumieniowym charakteryzują się wysoką przepustowością,
krótkimi czasami odpowiedzi i odpornością na awarie.
Dane mogą pochodzić z różnych źródeł: czujniki, komputery, telefony.
Możliwe jest tworzenie i wykonywanie analiz w czasie rzeczywistym,
dane przetwarzane są na bieżąco,
bezpośrednio po ich otrzymaniu.

Jednym z zagadnień związanych z przetwarzaniem danych jest wykrywanie zmian (sytuacji nietypowych).
Przez lata powstało wiele prac starających się rozwiązać ten problem.
Większość z nich oparta jest na analizie całościowej,
tj. zestawy danych,
które poddane są analizie,
przygotowywane są wcześniej i nie ulegają zmianie w czasie.
Algorytmy nie są w stanie na bieżąco analizować napływających danych.

Tematem niniejszej pracy jest zagadnienie wykrywania zmian w przebiegach czasowych,
oparte na mechanizmach statystycznych.

Celem pracy jest stworzenie mechanizmów wykrywających sytuacje nietypowe
z wykorzystaniem technik analizy strumieniowej.
W ramach pracy zostały sprawdzone dostępne platformy streamingowe:
\begin{itemize}
  \item Esper,
  \item Apache Spark,
  \item Apache Storm
\end{itemize}
pod kątem przydatności.
Aby sprawdzić skuteczność analizy strumieniowej zostały zaimplementowane algorytmy Bayesa (\textit{Bayesian Online Changepoint Detection})
oraz ADWIN.
Algorytmy w ramach pracy zostały zaadaptowane do wersji strumieniowych oraz przygotowane pod kątem platformy Apache Storm.
Analiza skuteczności badanych algorytmów została przeprowadzona z wykorzystaniem danych wygenerowanych losowo jak i rzeczywistych.

Układ pracy jest następujący.
Rozdział drugi przybliża tematykę związaną z analizą strumieniową.
W tym samym rozdziale znajduję się także porównanie dostępnych platform.
W rozdziale trzecim przedstawiono teoretyczne aspekty związane z wykrywaniem zmian.
Rozdział czwarty z kolei dokładnie przedstawia wykorzystane algorytmy.
W rozdziale piątym znajdują się wyniki przeprowadzonych eksperymentów.
Ostatni rozdział stanowi podsumowanie.
W dodatku A znajduje spis zawartości płyty CD.
